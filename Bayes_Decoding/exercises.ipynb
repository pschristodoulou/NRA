{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "---\n",
    "\n",
    "You can find below the code that was used to generate the activity of place cells on a linear track.\n",
    "Use the code and the decoding procedure you lerned about in the lesson to explore how different features of the data impact our ability to decode position.\n",
    "In particular:\n",
    "\n",
    "A - Try to use different fractions of our data samples. How does the median error change when the the number of available sample gets larger? You do not need to re-generate any data, just randomly sub-sample the data to different fractions.\n",
    "\n",
    "B - How many place cells do we need to reliably decode position? Try to re-do the decoding using only 10 cell, then 20, and so on. How does the median error change? Does it reach an asymptote? (Also in this case, you do not need to re-generate the data, you can just select a random subset of cells each time)\n",
    "\n",
    "C - Generate new data using the code below, changing the firing rate noise (changing the value of the variable `noise firing_rate`). How does this noise impact the decoding? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "---\n",
    "In the loop implementation of the decoder, we used `poisson.logpmf(k,mu)` to calculate the log probability of observing $k$ spikes given an average firing rate of $\\mu$. \n",
    "This is mathematically equivalent to `np.log(poisson.pmf(k,mu))`, in which we calculate the probability, and then take the log.\n",
    "\n",
    "\n",
    "Re-run the decoding substituting this expression:\n",
    "\n",
    "```\n",
    "posterior[i] = sum(np.log(poisson.pmf(spikes_count[t_bin,:],firing_rate_maps[:,i]/fps)+pow(1,-15)))\n",
    "```\n",
    "\n",
    "To the line we are using to calculate the posterior.\n",
    "Do you see any difference in the results? What do you think this is due to?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "---\n",
    "A - Estimate the quality of the sequence detection methods we saw in the lesson. How many false poistive does it find? How many false negatives?\n",
    "\n",
    "B - Investigate the effect of `noise_x_react` and `noise_t_react` on the false positive rate and the false negative rate of our detection procedure.\n",
    "\n",
    "C - What kind of sequence can our methods detect? What kind of activity, despide being sequential, could escape our detection method? Would you have an idea for a different method for sequence detection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import scipy.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "track_length = 200. # the length of our linear track (eg in centimeter)\n",
    "average_firing_rate = 5 # the peak firing rate, averaged across the population \n",
    "n_cells = 100 # how many cells we are recording\n",
    "pf_centers = np.random.rand(n_cells) * track_length # the centers of the place fields for all cells drawn randomly with a uniform distribution on the track\n",
    "pf_size = np.random.gamma(10, size=n_cells) # the size (width) of the place fields, drawn randomly from a gamma distribution \n",
    "pf_rate = np.random.exponential(scale=average_firing_rate, size=n_cells) # the peak firing rate for each cell, drawn from an exponential distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0., 200.)\n",
    "true_firing_rate_maps = np.zeros((n_cells, len(bins)))\n",
    "for i in range(n_cells):\n",
    "    true_firing_rate_maps[i,:] = pf_rate[i] * np.exp(-((bins-pf_centers[i])**2)/(2*pf_size[i]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE TRAJECTORY\n",
    "\n",
    "n_runs = 10\n",
    "use_stops = False\n",
    "av_running_speed = 10 # the average running speed (in cm/s)\n",
    "fps = 10 # the number of \"video frames\" per second \n",
    "running_speed_a = np.random.chisquare(10, size=n_runs) # running speed in the two directions\n",
    "running_speed_b = np.random.chisquare(10, size=n_runs) \n",
    "\n",
    "stopping_time_a = np.random.chisquare(15, size=n_runs) # the time the mouse will spend at the two ends of the track\n",
    "stopping_time_b = np.random.chisquare(15, size=n_runs)\n",
    "\n",
    "x = np.array([])\n",
    "\n",
    "\n",
    "for i in range(n_runs):\n",
    "    stop1 = np.ones((int(stopping_time_a[i]*fps),)) * 0.\n",
    "    run_length = len(bins) * fps / running_speed_a[i]\n",
    "    run1 = np.linspace(0., float(len(bins)-1), int(run_length))\n",
    "    stop2 = np.ones((int(stopping_time_b[i]*fps),)) * (len(bins)-1.)\n",
    "    run_length = len(bins) * fps / running_speed_b[i]\n",
    "    run2 = np.linspace(len(bins)-1., 0., int(run_length))\n",
    "    if use_stops:\n",
    "        x = np.concatenate((x, stop1, run1, stop2, run2))\n",
    "    else:\n",
    "         x = np.concatenate((x, run1, run2))\n",
    "t = np.arange(len(x))/fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 10000.\n",
    "t_sampling = np.arange(0, t[-1], 1. / sampling_rate)\n",
    "x_sampling = np.floor(np.interp(t_sampling, t, x))\n",
    "noise_firing_rate = 0.1 # the baseline noise firing rate\n",
    "spikes = []\n",
    "\n",
    "for i in range(n_cells):\n",
    "    inst_rate = true_firing_rate_maps[i,x_sampling.astype(np.int32)] + noise_firing_rate\n",
    "    spikes_loc = np.random.poisson(inst_rate/sampling_rate)\n",
    "    sp = np.argwhere(spikes_loc)\n",
    "    t_sp = t_sampling[sp]\n",
    "    spikes.append(t_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_name = 'linear_track_data.pickle' # change this name when you save new data\n",
    "\n",
    "out_data = {}\n",
    "out_data['x'] = x\n",
    "out_data['t'] = t\n",
    "out_data['spikes'] = spikes\n",
    "out_data['track_length'] = track_length\n",
    "out_data['fps'] = fps\n",
    "\n",
    "with open('data/'+file_name,'wb') as f:\n",
    "    pickle.dump(out_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec757111aa82fc412dab5a41ba1a33fdb6db5c8112df3ff06fec0dbff050b412"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
