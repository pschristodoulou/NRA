{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# generation of the stimulus \n",
    "\n",
    "duration = 100.\n",
    "dt = .1\n",
    "std_dev = 1.\n",
    "vf_size = (15,15)\n",
    "n_bins = round(duration / float(dt))\n",
    "\n",
    "\n",
    "S = std_dev * np.random.randn(n_bins,vf_size[0],vf_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = vf_size # size in pixel of our receptive field\n",
    "mu = (8, 8) # center of the gabor pathc\n",
    "sigma = (4,4) #size of the gabor patch\n",
    "angle = 45 # orientation of the gabor patch\n",
    "frequency = .085 # spatial frequency of the gabor patch\n",
    "phase = 0 # pahse of the gabor pathc\n",
    "\n",
    "\n",
    "xx, yy = np.meshgrid(1. + np.arange(size[0]),\n",
    "                         1. + np.arange(size[1]))\n",
    "\n",
    "# Gaussian envelope\n",
    "G = np.exp(- np.power(xx - mu[0], 2) / (2. * sigma[0])\n",
    "            - np.power(yy - mu[1], 2) / (2. * sigma[1]))\n",
    "\n",
    "# spatial modulation\n",
    "phi = np.deg2rad(angle)\n",
    "xxr = xx * np.cos(phi)\n",
    "yyr = yy * np.sin(phi)\n",
    "xyr = (xxr + yyr) * 2. * np.pi * 2. * frequency\n",
    "Sn = np.cos(xyr + phase)\n",
    "\n",
    "K = G * Sn\n",
    "K /= np.amax(np.abs(K))\n",
    "\n",
    "plt.imshow(K)\n",
    "plt.title(r'Receptive field $\\bf{k}$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inhomogeneous_poisson_spikes(lamda, dt): # firing rate and time interval\n",
    "\n",
    "    n_bins = lamda.shape[0]\n",
    "    bins = np.arange(n_bins+1)*dt\n",
    "\n",
    "    # generate Poisson distributed numbers for all bins with the max. intensity (lamda_max)\n",
    "    lamda_max = np.max(lamda)\n",
    "    poisson_numbers = np.random.poisson(lamda_max, size=n_bins) # This is the number of \n",
    "                                                                # spikes generated in bin i assuming the maximum rate Î»_max.\n",
    "\n",
    "    # throw away numbers depending on the actual intensity (\"thinning\")\n",
    "    spike_times = []\n",
    "    prob = lamda / lamda_max  # acceptance probability vector depending on lamda nature\n",
    "    for i in range(n_bins):\n",
    "        \n",
    "        # number of spikes to keep in this bin\n",
    "        n = np.sum(np.random.rand(poisson_numbers[i]) < prob[i])  # random vector of length poisson_numbers[i]\n",
    "        n_s = int(round(n * dt))\n",
    "\n",
    "        # This line generates n_s random spike times scaled by dt within the bin starting at bins[i]\n",
    "        ts = bins[i] + np.random.rand(n_s)*dt\n",
    "\n",
    "        spike_times.extend(ts)\n",
    "\n",
    "    return np.asarray(spike_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m spike_rate = \u001b[32m5\u001b[39m \u001b[38;5;66;03m# average firing rate \u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# flatten the matrices in to 1d array for convenience\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m K_flat = \u001b[43mK\u001b[49m.ravel()\n\u001b[32m      5\u001b[39m K_flat = np.hstack((K.flat, offset))\n\u001b[32m      7\u001b[39m S_flat = S.reshape(S.shape[\u001b[32m0\u001b[39m],S.shape[\u001b[32m1\u001b[39m]*S.shape[\u001b[32m2\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "spike_rate = 5 # average firing rate \n",
    "\n",
    "# flatten the matrices in to 1d array for convenience\n",
    "K_flat = K.ravel()\n",
    "K_flat = np.hstack((K.flat, offset))\n",
    "\n",
    "S_flat = S.reshape(S.shape[0],S.shape[1]*S.shape[2])\n",
    "S_flat = np.hstack((S_flat, np.ones((n_bins, 1))))\n",
    "\n",
    "\n",
    "# 1. linear stage\n",
    "ks = np.dot(K_flat, S_flat.T)\n",
    "\n",
    "# 2. nonlinear stage (for a linear model: f -> identity function)\n",
    "lamda = np.exp(ks)\n",
    "\n",
    "# lamda * dt is the number of spikes in the different bins (but keep in mind that the Poisson process\n",
    "# is a stochastic process so the actual number will differ for every draw). Thus, the sum of the product \n",
    "# across all bins gives the expected number of spikes for the whole draw.\n",
    "expected_rate = np.sum(lamda*dt) / duration\n",
    "lamda *= (spike_rate / expected_rate)\n",
    "\n",
    "# generate spike times using an inhomogeneous Poisson process\n",
    "spike_times = generate_inhomogeneous_poisson_spikes(lamda, dt)\n",
    "\n",
    "# compute spike counts in the different time bins\n",
    "spike_counts = np.histogram(spike_times,\n",
    "                            bins=np.arange(n_bins+1)*dt)[0]\n",
    "\n",
    "print(\"average spike rate: %0.2f spikes per second\" % (len(spike_times) / duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "---\n",
    "Determine the effect of stimulus sequence duration on RF estimates. To do this, repeat the above steps for different durations (5 s, 10 s, 20 s, 40 s, 80 s, 160 s, 320 s, 640 s). Compute the Pearson correlation between true and estimated RFs for each duration to quantify the accuracy of the estimator. The Pearson correlation $\\mathrm{cc}$ is defined as\n",
    "$$\n",
    "\\mathrm{cc} = \\frac{\\mathbf{k}_\\mathrm{true}^T \\hat{\\mathbf{k}}}{\\lVert \\mathbf{k}_\\mathrm{true} \\rVert \\lVert \\hat{\\mathbf{k}} \\rVert}\n",
    "$$\n",
    "where $\\lVert \\cdot \\rVert$ is the L2-norm (vector length).\n",
    "As the response generation process is stochastic, compute the average correlation across 10 realizations for the same duration and plot the average correlation as a function of duration. How is the recording duration related to the ability to recover the true RF? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "---\n",
    "Determine the effect of response noise ($\\sigma^2$) on RF estimates. Try different value for the noise variance in the simulations, e.g., 0, 2, 4, 6, 8, and 10 for a duration of 100 s. As in the previous excercise, repeatedly estimate RF parameters for each condition (10 times) but this time also plot the standard deviation of the correlations across the different runs for each condition."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "---\n",
    "Look at the analytical derivation of the log-likelihood for the poisson GLM.\n",
    "Which of the terms are required for maximizing the likelihood with respect to $\\mathbf{k}$ and which terms can be ignored? **Note:** due to the independence of spikes in the different bins, the likelihood can be written as $P(R | S, \\mathbf{k}) = \\prod_t^T P(r_t | \\mathbf{s}_t, \\mathbf{k})$. The log turns the product into a sum which makes life much easier. \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "---\n",
    "Explore the effect of the data duration and the firing rate on the goodness of fit of the Poisson GLM.\n",
    "\n",
    "A - Generate data with durations of 10,20,50,100 and 200 seconds. Fit the model on each dataset and plot the fitted parameters.\n",
    "Use the pearson correlation as a proxy of the goodness of fit, and plot it as a function of the duration of the data.\n",
    "\n",
    "B - Fix the duration to 100s, and change the average firing rate of the simulation. How does the fit perform for different firing rates? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
